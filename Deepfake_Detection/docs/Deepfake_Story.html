<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
        content="Deepfake Defender: Multi-Modal Detection System using CNN and ResNet for audio-visual forensics.">
    <title>Deepfake Defender: Multi-Modal Detection | Case Study</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <style>
        :root {
            --bg-color: #0B0C10;
            --card-bg: #1F2833;
            --text-primary: #C5C6C7;
            --text-highlight: #FFFFFF;
            --accent-color: #66FCF1;
            --accent-dark: #45A29E;
            --gradient: linear-gradient(135deg, #66FCF1 0%, #45A29E 100%);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
            background-color: var(--bg-color);
            color: var(--text-primary);
            line-height: 1.7;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 2rem;
        }

        /* Hero Section */
        .hero {
            min-height: 60vh;
            display: flex;
            flex-direction: column;
            justify-content: center;
            padding: 4rem 2rem;
            background: linear-gradient(135deg, rgba(102, 252, 241, 0.05) 0%, var(--bg-color) 100%);
            border-bottom: 1px solid rgba(102, 252, 241, 0.2);
        }

        .hero h1 {
            font-size: clamp(2.5rem, 6vw, 4rem);
            font-weight: 700;
            background: var(--gradient);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            margin-bottom: 1rem;
        }

        .hero .tagline {
            font-size: 1.25rem;
            color: var(--text-highlight);
            margin-bottom: 0.5rem;
        }

        .hero .subtitle {
            font-size: 1rem;
            color: var(--text-primary);
            margin-bottom: 2rem;
        }

        .tech-stack {
            display: flex;
            flex-wrap: wrap;
            gap: 0.5rem;
            margin-bottom: 2rem;
        }

        .tech-tag {
            padding: 0.35rem 0.75rem;
            background: rgba(102, 252, 241, 0.1);
            border: 1px solid rgba(102, 252, 241, 0.3);
            border-radius: 4px;
            font-size: 0.8rem;
            color: var(--accent-color);
        }

        .btn-group {
            display: flex;
            gap: 1rem;
            flex-wrap: wrap;
        }

        .btn-primary {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.875rem 1.75rem;
            background: var(--gradient);
            color: var(--bg-color);
            text-decoration: none;
            font-weight: 600;
            border-radius: 8px;
            transition: transform 0.2s ease, box-shadow 0.2s ease;
        }

        .btn-primary:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 30px rgba(102, 252, 241, 0.3);
        }

        .btn-secondary {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.875rem 1.75rem;
            background: transparent;
            color: var(--accent-color);
            border: 2px solid var(--accent-color);
            text-decoration: none;
            font-weight: 600;
            border-radius: 8px;
            transition: all 0.2s ease;
        }

        .btn-secondary:hover {
            background: rgba(102, 252, 241, 0.1);
            transform: translateY(-2px);
        }

        /* Sections */
        section {
            padding: 4rem 0;
        }

        .section-title {
            font-size: 1.75rem;
            font-weight: 600;
            color: var(--text-highlight);
            margin-bottom: 1.5rem;
            display: flex;
            align-items: center;
            gap: 0.75rem;
        }

        .section-title::before {
            content: '';
            width: 30px;
            height: 3px;
            background: var(--gradient);
            border-radius: 2px;
        }

        p {
            margin-bottom: 1.25rem;
        }

        /* Cards */
        .card {
            background: var(--card-bg);
            border: 1px solid rgba(102, 252, 241, 0.15);
            border-radius: 12px;
            padding: 1.5rem;
            margin-bottom: 1.5rem;
        }

        .card h3 {
            color: var(--text-highlight);
            font-size: 1.1rem;
            margin-bottom: 0.75rem;
        }

        .card-icon {
            font-size: 1.5rem;
            margin-bottom: 0.5rem;
        }

        /* Component Grid */
        .component-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1rem;
            margin: 2rem 0;
        }

        .component-card {
            background: var(--card-bg);
            border: 1px solid rgba(102, 252, 241, 0.2);
            border-radius: 12px;
            padding: 1.5rem;
            text-align: center;
            transition: all 0.3s ease;
        }

        .component-card:hover {
            border-color: var(--accent-color);
            transform: translateY(-5px);
        }

        .component-card .icon {
            font-size: 2rem;
            margin-bottom: 0.5rem;
        }

        .component-card h4 {
            color: var(--text-highlight);
            font-size: 1rem;
            margin-bottom: 0.5rem;
        }

        .component-card p {
            font-size: 0.85rem;
            color: var(--text-primary);
            margin: 0;
        }

        /* Architecture Diagram */
        .diagram-container {
            background: var(--card-bg);
            border: 1px solid rgba(102, 252, 241, 0.15);
            border-radius: 12px;
            padding: 2rem;
            margin: 2rem 0;
            text-align: center;
        }

        .mermaid {
            display: flex;
            justify-content: center;
        }

        /* Feature List */
        .feature-list {
            list-style: none;
            padding: 0;
        }

        .feature-list li {
            padding: 0.75rem 0;
            padding-left: 2rem;
            position: relative;
            border-bottom: 1px solid rgba(102, 252, 241, 0.1);
        }

        .feature-list li::before {
            content: '‚úì';
            position: absolute;
            left: 0;
            color: var(--accent-color);
            font-weight: bold;
        }

        /* Impact Section */
        .impact-box {
            background: linear-gradient(135deg, rgba(102, 252, 241, 0.1) 0%, var(--card-bg) 100%);
            border: 2px solid var(--accent-color);
            border-radius: 12px;
            padding: 2rem;
            margin: 2rem 0;
        }

        .impact-box h3 {
            color: var(--accent-color);
            margin-bottom: 1rem;
        }

        /* Footer */
        footer {
            text-align: center;
            padding: 3rem 2rem;
            border-top: 1px solid rgba(102, 252, 241, 0.1);
            color: var(--text-primary);
            font-size: 0.9rem;
        }

        footer a {
            color: var(--accent-color);
            text-decoration: none;
        }

        /* Responsive */
        @media (max-width: 768px) {
            .hero {
                min-height: auto;
                padding: 3rem 1.5rem;
            }

            section {
                padding: 3rem 0;
            }

            .container {
                padding: 0 1.5rem;
            }
        }
    </style>
</head>

<body>
    <!-- Hero -->
    <header class="hero">
        <div class="container">
            <h1>üõ°Ô∏è Deepfake Defender</h1>
            <p class="tagline">Multi-Modal Detection System for AI-Generated Media</p>
            <p class="subtitle">Combining audio and visual forensic models to combat misinformation and detect
                manipulated content.</p>
            <div class="tech-stack">
                <span class="tech-tag">PyTorch</span>
                <span class="tech-tag">OpenCV</span>
                <span class="tech-tag">FFmpeg</span>
                <span class="tech-tag">CNN</span>
                <span class="tech-tag">ResNet</span>
                <span class="tech-tag">Python</span>
            </div>
            <div class="btn-group">
                <a href="https://github.com/potlurisravanth-png/deepfake-detection-lav-df" target="_blank"
                    class="btn-primary">
                    üíª View on GitHub
                </a>
                <a href="DeepFakeProject_Report.html" target="_blank" class="btn-secondary">
                    üìÑ Full Notebook Report
                </a>
            </div>
        </div>
    </header>

    <main>
        <!-- Problem Statement -->
        <section>
            <div class="container">
                <h2 class="section-title">The Problem</h2>
                <p>Deepfakes are becoming increasingly sophisticated and accessible. AI-generated fake videos can:</p>
                <ul class="feature-list">
                    <li><strong>Spread misinformation:</strong> Fabricated videos of public figures can influence
                        elections and public opinion</li>
                    <li><strong>Enable fraud:</strong> Voice cloning and face-swaps can be used for identity theft and
                        scams</li>
                    <li><strong>Damage reputations:</strong> Non-consensual fake content can destroy personal and
                        professional lives</li>
                    <li><strong>Undermine trust:</strong> The existence of deepfakes makes people question authentic
                        media</li>
                </ul>
            </div>
        </section>

        <!-- Solution Overview -->
        <section style="background: var(--card-bg);">
            <div class="container">
                <h2 class="section-title">The Solution</h2>
                <p><strong>Deepfake Defender</strong> uses a <strong>multi-modal approach</strong> that analyzes both
                    visual and audio streams simultaneously. By combining two specialized neural networks, it achieves
                    higher accuracy than single-modal systems.</p>

                <div class="component-grid">
                    <div class="component-card">
                        <div class="icon">üëÅÔ∏è</div>
                        <h4>Visual Stream</h4>
                        <p>CNN analyzes facial features and micro-expressions</p>
                    </div>
                    <div class="component-card">
                        <div class="icon">üîä</div>
                        <h4>Audio Stream</h4>
                        <p>ResNet detects synthetic voice artifacts</p>
                    </div>
                    <div class="component-card">
                        <div class="icon">üîó</div>
                        <h4>Fusion Layer</h4>
                        <p>Combines both streams for final prediction</p>
                    </div>
                    <div class="component-card">
                        <div class="icon">üìä</div>
                        <h4>Probability Score</h4>
                        <p>Confidence rating (0-100%) for detection</p>
                    </div>
                </div>
            </div>
        </section>

        <!-- Architecture -->
        <section>
            <div class="container">
                <h2 class="section-title">System Architecture</h2>
                <p>The model processes video through parallel pipelines, extracting faces for visual analysis and audio
                    spectrograms for voice analysis, then fuses the results.</p>

                <div class="diagram-container">
                    <div class="mermaid">
                        graph LR
                        A[üé¨ Input Video] --> B(üé≠ Face Extraction)
                        A --> C(üéµ Audio Extraction)
                        B --> D[üëÅÔ∏è Visual CNN]
                        C --> E[üîä Audio ResNet]
                        D --> F{üîó Fusion Layer}
                        E --> F
                        F --> G[üìä Probability Score]
                    </div>
                </div>
            </div>
        </section>

        <!-- Key Features -->
        <section style="background: var(--card-bg);">
            <div class="container">
                <h2 class="section-title">Key Features</h2>
                <div class="card">
                    <div class="card-icon">üéØ</div>
                    <h3>Multi-Modal Detection</h3>
                    <p>Analyzes both visual artifacts (blinking patterns, lip sync) and audio artifacts (unnatural
                        frequencies, voice inconsistencies) for comprehensive detection.</p>
                </div>
                <div class="card">
                    <div class="card-icon">üìÅ</div>
                    <h3>LAV-DF Dataset Training</h3>
                    <p>Trained on the LAV-DF (Large-scale Audio-Visual Deepfake) dataset, featuring diverse manipulation
                        techniques and real-world scenarios.</p>
                </div>
                <div class="card">
                    <div class="card-icon">‚ö°</div>
                    <h3>Real-Time Processing</h3>
                    <p>Optimized inference pipeline enables near real-time analysis of video content for rapid
                        verification.</p>
                </div>
                <div class="card">
                    <div class="card-icon">üìà</div>
                    <h3>Confidence Scoring</h3>
                    <p>Returns a probability score with detailed breakdown of visual and audio contributions to the
                        detection decision.</p>
                </div>
            </div>
        </section>

        <!-- Impact -->
        <section>
            <div class="container">
                <h2 class="section-title">Impact & Results</h2>
                <div class="impact-box">
                    <h3>üéØ Detection Capabilities</h3>
                    <ul class="feature-list">
                        <li>Identifies face-swap deepfakes with high accuracy</li>
                        <li>Detects synthetic voice and lip-sync inconsistencies</li>
                        <li>Flags manipulated content for further review</li>
                        <li>Provides explainable results showing which modality triggered detection</li>
                    </ul>
                </div>
            </div>
        </section>

        <!-- Tech Stack -->
        <section style="background: var(--card-bg);">
            <div class="container">
                <h2 class="section-title">Technology Stack</h2>
                <div class="component-grid">
                    <div class="component-card">
                        <div class="icon">üî•</div>
                        <h4>PyTorch</h4>
                        <p>Deep learning framework</p>
                    </div>
                    <div class="component-card">
                        <div class="icon">üëÅÔ∏è</div>
                        <h4>OpenCV</h4>
                        <p>Computer vision processing</p>
                    </div>
                    <div class="component-card">
                        <div class="icon">üé¨</div>
                        <h4>FFmpeg</h4>
                        <p>Audio/video extraction</p>
                    </div>
                    <div class="component-card">
                        <div class="icon">üß†</div>
                        <h4>CNN + ResNet</h4>
                        <p>Visual & audio models</p>
                    </div>
                    <div class="component-card">
                        <div class="icon">üêç</div>
                        <h4>Python</h4>
                        <p>Core implementation</p>
                    </div>
                    <div class="component-card">
                        <div class="icon">üìì</div>
                        <h4>Jupyter</h4>
                        <p>Research & experimentation</p>
                    </div>
                </div>
            </div>
        </section>
    </main>

    <footer>
        <p>Built by <a href="https://potlurisravanth-png.github.io/sravanth-dev-portfolio/">Sravanth Potluri</a> | <a
                href="https://github.com/potlurisravanth-png/deepfake-detection-lav-df">View Source Code</a> | <a
                href="DeepFakeProject_Report.html">Full Notebook Report</a></p>
    </footer>

    <script>
        mermaid.initialize({
            startOnLoad: true,
            theme: 'dark',
            themeVariables: {
                primaryColor: '#1F2833',
                primaryTextColor: '#C5C6C7',
                primaryBorderColor: '#66FCF1',
                lineColor: '#66FCF1',
                secondaryColor: '#0B0C10',
                tertiaryColor: '#1F2833'
            }
        });
    </script>
</body>

</html>